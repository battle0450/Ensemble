{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information gain(同質)(不檢測)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 8, 6, 11, 7, 10, 14, 13, 15, 4, 17, 16, 9, 3, 12, 1, 5]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 2 and input n_features is 18 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-fd3cc0947ef0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_train'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_train'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_predict_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'random_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0mrandom_predict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_predict_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#存每個Base預測x_test的結果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m#(每個基本模型的準確度)locals()['accuracy_'+str(i)]= metrics.accuracy_score(y_test,locals()['y_predict_'+str(i)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \"\"\"\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 2 and input n_features is 18 "
     ]
    }
   ],
   "source": [
    "####import####\n",
    "import math \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random  \n",
    "from pandas.core.frame import DataFrame\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import ensemble,metrics\n",
    "\n",
    "####讀檔####\n",
    "df = pd.read_csv('vehicle.csv')  \n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#離散化(kfold外)\n",
    "i_x=pd.DataFrame(columns=x.columns)\n",
    "for i in range(x.shape[1]):\n",
    "    temp_=x.iloc[:,i]\n",
    "    xd= pd.cut(temp_, 5,labels=range(1,6))\n",
    "    i_x.iloc[:,i]=xd\n",
    "\n",
    "\n",
    "####kfold####\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42) \n",
    "\n",
    "    ####參數####\n",
    "    ff=0 #feature從0開始跑 \n",
    "    m=5#基本模型數量\n",
    "    feature_number=2 #特徵數\n",
    "    random_predict=[]#預測x_train\n",
    "    d_random_predict=[]#預測d_x\n",
    "    \n",
    "    \n",
    "    ####測試多樣性的樣本####\n",
    "    #d_df=df.sample(frac=0.3, replace=False, random_state=1)\n",
    "    #d_x=d_df.iloc[:,:-1]\n",
    "    #d_y=d_df.iloc[:,-1]\n",
    "    d_x=x_train\n",
    "    d_y=y_train\n",
    "    \n",
    "    ####計算entropy####\n",
    "    #x\n",
    "    i_x_train=i_x.iloc[train_index] #676*18\n",
    "\n",
    "    #y\n",
    "    y_count=y_train.value_counts(normalize=True).sort_index()#數量/總數 並按index排序\n",
    "    entropy=0\n",
    "    for e in range(len(y_count)):\n",
    "        entropy+=-y_count[e]*(math.log(y_count[e],2))\n",
    "\n",
    "    #類別也變1,2,3...\n",
    "    i_y_train=y_train \n",
    "    for e in range(len(y_count)):\n",
    "        i_y_train=i_y_train.replace(y_count.index[e], e) \n",
    "\n",
    "    #每個特徵的排\n",
    "    e_rank=[]# 每個特徵的information gain\n",
    "    for e in range(i_x_train.shape[1]):#幾個特徵i_x_train.shape[1]\n",
    "        temp_feature=[]\n",
    "        temp_feature.append(i_y_train)\n",
    "        temp_feature.append(i_x_train.iloc[:,e])\n",
    "        temp_feature=DataFrame(temp_feature)\n",
    "\n",
    "        feature_count=i_x_train.iloc[:,e].value_counts().sort_index() #feature有幾個特徵值\n",
    "        e=0 #特徵的information gain\n",
    "        #print(feature_count.iloc[0])\n",
    "\n",
    "        for f in range(1,len(feature_count)+1):#1~5\n",
    "            temp_count_class=[]  #------------------------------\n",
    "            locals()['entropy_'+str(f)]=0 #------------------------------\n",
    "            for h in range(i_x_train.shape[0]):#677\n",
    "                if temp_feature.iloc[1,h]==f: #存所有特徵質為0的y\n",
    "                    temp_count_class.append(temp_feature.iloc[0,h])\n",
    "            \n",
    "            for h in range(len(y_count)):#0~3\n",
    "                if temp_count_class.count(h)!=0:\n",
    "                    locals()['entropy_'+str(f)]+=-(temp_count_class.count(h)/feature_count.iloc[0])*math.log(temp_count_class.count(h)/feature_count.iloc[0],2)\n",
    "        for f in range(1,len(feature_count)+1):#0~4\n",
    "            e+=feature_count.iloc[f-1]/i_x_train.shape[0]*locals()['entropy_'+str(f)]\n",
    "        e_rank.append(e)\n",
    "\n",
    "\n",
    "    rank=sorted(range(len(e_rank)), key=lambda k: e_rank[k]) #排序後的index \n",
    "    print(rank)\n",
    "\n",
    "\n",
    "    ####Bagging####\n",
    "    '''\n",
    "    random_1 = ensemble.BaggingClassifier(DecisionTreeClassifier(),n_estimators = 1)\n",
    "    random_fit_1 = random_1.fit(x_train, y_train)        \n",
    "    y_predict_1 = random_1.predict(x_test) \n",
    "    accuracy_1 = metrics.accuracy_score(y_test,y_predict_1)\n",
    "    print(\"random_1 : \",accuracy_1)\n",
    "    '''\n",
    "    feature_data=[]\n",
    "    for i in range(1):#(1,m+1)\n",
    "        for feature_point in range(ff,ff+feature_number):\n",
    "            feature_data.append(x_train.iloc[:,rank[feature_point]])\n",
    "        ff+=1\n",
    "        feature_data=DataFrame(feature_data).T\n",
    "        locals()['x_train'+str(i)]=feature_data\n",
    "        locals()['y_train'+str(i)]=y_train[locals()['x_train'+str(i)].index]\n",
    "        locals()['random_'+str(i)]=DecisionTreeClassifier()\n",
    "        locals()['random_'+str(i)].fit(locals()['x_train'+str(i)], locals()['y_train'+str(i)])\n",
    "        locals()['y_predict_'+str(i)]=locals()['random_'+str(i)].predict(x_test)\n",
    "        random_predict.append(locals()['y_predict_'+str(i)])#存每個Base預測x_test的結果\n",
    "        #(每個基本模型的準確度)locals()['accuracy_'+str(i)]= metrics.accuracy_score(y_test,locals()['y_predict_'+str(i)])\n",
    "        #(每個基本模型的準確度)print(i,\" : \" ,locals()['accuracy_'+str(i)])\n",
    "\n",
    "\n",
    "\n",
    "    ####acc####\n",
    "    #(樣本數) random_predict.shape[1] \n",
    "    #(模型數) random_predict.shape[0]\n",
    "    temp=[]\n",
    "    acc_count=0\n",
    "    random_predict=np.array(random_predict)#list轉array\n",
    "    for i in range(random_predict.shape[1]):\n",
    "        temp=[]\n",
    "        for j in range(random_predict.shape[0]):\n",
    "            temp.append(random_predict[j][i])\n",
    "        vote= max(temp,key=temp.count)\n",
    "        if vote==y_test.iloc[i]:\n",
    "            acc_count+=1\n",
    "\n",
    "    print(\"acc : \",acc_count/random_predict.shape[1] )\n",
    "\n",
    "\n",
    "    ####Diversity#### \n",
    "    d_random_predict.append(d_y) #第0列放實際值\n",
    "\n",
    "\n",
    "    '''    \n",
    "    d_random_predict.append(bag_1.predict(d_x))\n",
    "    '''\n",
    "    for i in range(1,11): #第1~10列放Model預測值\n",
    "        d_random_predict.append(locals()['random_'+str(i)].predict(d_x))\n",
    "        \n",
    "    d_random_predict=np.array(d_random_predict)#list轉array\n",
    "\n",
    "\n",
    "\n",
    "    #(樣本數) d_random_predict.shape[1] \n",
    "    #(模型數) d_random_predict.shape[0]\n",
    "\n",
    "\n",
    "    #轉為O或1\n",
    "    for i in range(d_random_predict.shape[1]):\n",
    "        for j in range(1,d_random_predict.shape[0]):\n",
    "            if d_random_predict[j][i]==d_random_predict[0][i]:\n",
    "                d_random_predict[j][i]=1 #預測正確\n",
    "            else:\n",
    "                d_random_predict[j][i]=0 #預測錯誤\n",
    "\n",
    "\n",
    "\n",
    "    #pi參數設定          \n",
    "    for i in range(d_random_predict.shape[0]):\n",
    "        locals()['p'+str(i)]=0\n",
    "    cfd=0\n",
    "\n",
    "    #計算pi\n",
    "    for i in range(d_random_predict.shape[1]):\n",
    "        count=0\n",
    "        for j in range(1,d_random_predict.shape[0]):\n",
    "            if d_random_predict[j][i]==0:\n",
    "                count+=1\n",
    "        '''\n",
    "        if count==0:\n",
    "            p0+=1\n",
    "        '''\n",
    "        for j in range(d_random_predict.shape[0]+1):\n",
    "            if count==j:\n",
    "                locals()['p'+str(j)]+=1\n",
    "\n",
    "\n",
    "    #數量/總數        \n",
    "    for i in range(d_random_predict.shape[0]):\n",
    "        locals()['p'+str(i)]=locals()['p'+str(i)]/d_random_predict.shape[1]\n",
    "\n",
    "    #計算CFD\n",
    "    x1=0\n",
    "    x2=0\n",
    "\n",
    "    if p0==1:\n",
    "        cfd=0\n",
    "    else:\n",
    "        x1=1/(1-p0)\n",
    "        for i in range(1,d_random_predict.shape[0]):\n",
    "            x2=(d_random_predict.shape[0]-i)/(d_random_predict.shape[0]-1)*locals()['p'+str(i)]+x2\n",
    "        cfd=x1*x2   \n",
    "\n",
    "    print(\"cfd : \",cfd)\n",
    "    \n",
    "    \n",
    "#print(x_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 8, 6, 11, 7, 15, 14, 10, 13, 4, 9, 1, 17, 3, 16, 12, 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#計算entropy\n",
    "\n",
    "#x\n",
    "i_x_train=.iloc[train_index]\n",
    "\n",
    "#y\n",
    "y_count=y_train.value_counts(normalize=True).sort_index()#數量/總數 並按index排序\n",
    "entropy=0\n",
    "for e in range(len(y_count)):\n",
    "    entropy+=-y_count[e]*(math.log(y_count[e],2))\n",
    "    \n",
    "#類別也變1,2,3...\n",
    "i_y_train=y_train \n",
    "for e in range(len(y_count)):\n",
    "    i_y_train=i_y_train.replace(y_count.index[e], e) \n",
    "\n",
    "\n",
    "#每個特徵的排\n",
    "e_rank=[]# 每個特徵的information gain\n",
    "for e in range(i_x_train.shape[1]):#幾個特徵\n",
    "    temp_feature=[]\n",
    "    temp_feature.append(i_y_train)\n",
    "    temp_feature.append(i_x_train.iloc[:,e])\n",
    "    feature_count=i_x_train.iloc[:,e].value_counts().sort_index() #feature有幾個特徵值\n",
    "    e=0 #特徵的information gain\n",
    "    #print(feature_count.iloc[0])\n",
    "    for f in range(len(feature_count)):#0~4\n",
    "        temp_count_class=[]  #------------------------------\n",
    "        locals()['entropy_'+str(f)]=0 #------------------------------\n",
    "        for h in range(i_x_train.shape[0]):#677\n",
    "            if temp_feature[1][h]==f:\n",
    "                temp_count_class.append(temp_feature[0][h])\n",
    "        for h in range(len(y_count)):#0~3\n",
    "            if temp_count_class.count(h)!=0:\n",
    "                locals()['entropy_'+str(f)]+=-(temp_count_class.count(h)/feature_count.iloc[0])*math.log(temp_count_class.count(h)/feature_count.iloc[0],2)\n",
    "    for f in range(len(feature_count)):#0~4\n",
    "        e+=feature_count.iloc[f]/i_x_train.shape[0]*locals()['entropy_'+str(f)]\n",
    "    e_rank.append(e)\n",
    "    \n",
    "rank=sorted(range(len(e_rank)), key=lambda k: e_rank[k]) #排序後的index \n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    COMPACTNESS CIRCULARITY DISTANCE CIRCULARITY RADIUS RATIO  \\\n",
      "0             3           3                    3            2   \n",
      "1             2           2                    4            1   \n",
      "2             4           4                    5            3   \n",
      "3             3           2                    3            2   \n",
      "4             2           3                    3            3   \n",
      "..          ...         ...                  ...          ...   \n",
      "841           3           2                    4            2   \n",
      "842           2           3                    4            2   \n",
      "843           4           5                    5            3   \n",
      "844           2           1                    3            1   \n",
      "845           2           1                    2            1   \n",
      "\n",
      "    PR.AXIS ASPECT RATIO MAX.LENGTH ASPECT RATIO SCATTER RATIO ELONGATEDNESS  \\\n",
      "0                      2                       1             2             3   \n",
      "1                      1                       1             2             3   \n",
      "2                      2                       1             4             1   \n",
      "3                      1                       1             2             3   \n",
      "4                      4                       5             2             3   \n",
      "..                   ...                     ...           ...           ...   \n",
      "841                    1                       1             2             2   \n",
      "842                    2                       1             2             3   \n",
      "843                    2                       1             4             1   \n",
      "844                    1                       1             1             4   \n",
      "845                    1                       1             1             5   \n",
      "\n",
      "    PR.AXIS RECTANGULARITY MAX.LENGTH RECTANGULARITY SCALED VARIANCE   \\\n",
      "0                        2                         3                2   \n",
      "1                        1                         2                2   \n",
      "2                        3                         3                3   \n",
      "3                        1                         2                1   \n",
      "4                        1                         2                3   \n",
      "..                     ...                       ...              ...   \n",
      "841                      2                         2                2   \n",
      "842                      2                         3                2   \n",
      "843                      4                         4                3   \n",
      "844                      1                         1                1   \n",
      "845                      1                         1                1   \n",
      "\n",
      "    SCALED VARIANCE SCALED RADIUS OF GYRATION SKEWNESS ABOUT SKEWNESS ABOUT.1  \\\n",
      "0                 2                         3              1                2   \n",
      "1                 1                         2              1                3   \n",
      "2                 3                         4              1                4   \n",
      "3                 1                         1              1                2   \n",
      "4                 1                         3              5                3   \n",
      "..              ...                       ...            ...              ...   \n",
      "841               2                         2              1                2   \n",
      "842               2                         3              1                1   \n",
      "843               4                         3              1                1   \n",
      "844               1                         2              1                1   \n",
      "845               1                         1              1                1   \n",
      "\n",
      "    KURTOSIS ABOUT KURTOSIS ABOUT.1 HOLLOWS RATIO  \n",
      "0                2                2             3  \n",
      "1                2                3             3  \n",
      "2                2                2             3  \n",
      "3                2                4             5  \n",
      "4                2                1             1  \n",
      "..             ...              ...           ...  \n",
      "841              4                2             3  \n",
      "842              3                2             3  \n",
      "843              1                2             4  \n",
      "844              4                3             3  \n",
      "845              3                2             2  \n",
      "\n",
      "[846 rows x 18 columns]\n",
      "[2, 0, 8, 6, 11, 7, 10, 14, 13, 15, 4, 17, 16, 9, 3, 12, 1, 5]\n",
      "[2, 0, 8, 6, 11, 7, 14, 15, 10, 13, 4, 9, 16, 1, 17, 3, 12, 5]\n",
      "[2, 0, 6, 8, 11, 7, 14, 15, 13, 10, 4, 9, 3, 17, 1, 12, 16, 5]\n",
      "[2, 0, 6, 8, 11, 7, 14, 10, 15, 13, 4, 9, 1, 12, 3, 17, 16, 5]\n",
      "[2, 0, 8, 6, 11, 7, 15, 14, 10, 13, 4, 9, 1, 17, 3, 16, 12, 5]\n"
     ]
    }
   ],
   "source": [
    "####import####\n",
    "import math \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random  \n",
    "from pandas.core.frame import DataFrame\n",
    "import numpy as np \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import ensemble,metrics\n",
    "\n",
    "####讀檔####\n",
    "df = pd.read_csv('vehicle.csv')  \n",
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "\n",
    "####測試多樣性的樣本####\n",
    "d_df=df.sample(frac=0.3, replace=False, random_state=1)\n",
    "d_x=d_df.iloc[:,:-1]\n",
    "d_y=d_df.iloc[:,-1]\n",
    "\n",
    "\n",
    "#離散化(kfold外)\n",
    "i_x=pd.DataFrame(columns=x_train.columns)\n",
    "for i in range(x.shape[1]):\n",
    "    temp_=x.iloc[:,i]\n",
    "    xd= pd.cut(temp_, 5,labels=range(1,6))\n",
    "    i_x.iloc[:,i]=xd\n",
    "\n",
    "print(i_x)\n",
    "####kfold####\n",
    "kf=KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "for train_index, test_index in kf.split(x):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42) \n",
    "\n",
    "    ####參數####\n",
    "    m=10#基本模型數量\n",
    "    random_predict=[]#預測x_train\n",
    "    d_random_predict=[]#預測d_x\n",
    "\n",
    "    \n",
    "    ####計算entropy####\n",
    "    #x\n",
    "    i_x_train=i_x.iloc[train_index] #676*18\n",
    "\n",
    "    #y\n",
    "    y_count=y_train.value_counts(normalize=True).sort_index()#數量/總數 並按index排序\n",
    "    entropy=0\n",
    "    for e in range(len(y_count)):\n",
    "        entropy+=-y_count[e]*(math.log(y_count[e],2))\n",
    "\n",
    "    #類別也變1,2,3...\n",
    "    i_y_train=y_train \n",
    "    for e in range(len(y_count)):\n",
    "        i_y_train=i_y_train.replace(y_count.index[e], e) \n",
    "\n",
    "    #每個特徵的排\n",
    "    e_rank=[]# 每個特徵的information gain\n",
    "    for e in range(i_x_train.shape[1]):#幾個特徵i_x_train.shape[1]\n",
    "        temp_feature=[]\n",
    "        temp_feature.append(i_y_train)\n",
    "        temp_feature.append(i_x_train.iloc[:,e])\n",
    "        temp_feature=DataFrame(temp_feature)\n",
    "\n",
    "        feature_count=i_x_train.iloc[:,e].value_counts().sort_index() #feature有幾個特徵值\n",
    "        e=0 #特徵的information gain\n",
    "        #print(feature_count.iloc[0])\n",
    "\n",
    "        for f in range(1,len(feature_count)+1):#1~5\n",
    "            temp_count_class=[]  #------------------------------\n",
    "            locals()['entropy_'+str(f)]=0 #------------------------------\n",
    "            for h in range(i_x_train.shape[0]):#677\n",
    "                if temp_feature.iloc[1,h]==f: #存所有特徵質為1的y\n",
    "                    temp_count_class.append(temp_feature.iloc[0,h])\n",
    "            \n",
    "            for h in range(len(y_count)):#0~3\n",
    "                if temp_count_class.count(h)!=0:\n",
    "                    locals()['entropy_'+str(f)]+=-(temp_count_class.count(h)/feature_count.iloc[0])*math.log(temp_count_class.count(h)/feature_count.iloc[0],2)\n",
    "        for f in range(1,len(feature_count)+1):#0~4\n",
    "            e+=feature_count.iloc[f-1]/i_x_train.shape[0]*locals()['entropy_'+str(f)]\n",
    "        e_rank.append(e)\n",
    "\n",
    "\n",
    "    rank=sorted(range(len(e_rank)), key=lambda k: e_rank[k]) #排序後的index \n",
    "    print(rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   locals()['entropy_'+str(f)]=0\n",
    "        for g in range(len(y_count)):#0~3\n",
    "            count=0\n",
    "           \n",
    "                if temp_feature[0][h]==g and :\n",
    "                    count+=1\n",
    "        locals()['entropy_'+str(f)]+=-(count/feature_count[f])*math.log((count/feature_count[f]),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "ll=Counter(x.iloc[:,0])\n",
    "print(ll)\n",
    "ll.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,0].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####參數####\n",
    "m=10#基本模型數量\n",
    "bag_predict=[]#預測x_train\n",
    "d_bag_predict=[]#預測d_x\n",
    "\n",
    "b=ensemble.BaggingClassifier(DecisionTreeClassifier(),n_estimators = 10)\n",
    "b.fit(x_train, y_train)\n",
    "estimators_samples = b.estimators_samples_\n",
    "estimators_samples=np.array(estimators_samples)\n",
    "accuracy=b.score(x_test,y_test)\n",
    "print(accuracy)\n",
    "\n",
    "#y_predict= b.predict(x_test) \n",
    "#accuracy = metrics.accuracy_score(y_test,y_predict)\n",
    "#print(\"Bagging: \",accuracy)\n",
    "\n",
    "#處理子訓練資料\n",
    "for i in range(0,estimators_samples.shape[0]):\n",
    "    a=estimators_samples[i]\n",
    "    locals()['base'+str(i+1)+'_x_train']=x_train.iloc[a]\n",
    "    locals()['base'+str(i+1)+'_y_train']=y_train.iloc[a]\n",
    "    locals()['bag_fit_'+str(i+1)]=locals()['bag_'+str(i+1)].fit(locals()['base'+str(i+1)+'_x_train'], locals()['base'+str(i+1)+'_y_train']) \n",
    "    locals()['y_predict_'+str(i+1)]=locals()['bag_'+str(i+1)].predict(x_test)\n",
    "    bag_predict.append(locals()['y_predict_'+str(i+1)])#存每個Base預測x_test的結果\n",
    "    \n",
    "    \n",
    "#計算ACC\n",
    "temp=[]#每個模型對某一樣本的預測\n",
    "acc_count=0\n",
    "bag_predict=np.array(bag_predict)#list轉array\n",
    "for i in range(bag_predict.shape[1]):\n",
    "    temp=[]\n",
    "    for j in range(bag_predict.shape[0]):\n",
    "        temp.append(bag_predict[j][i])\n",
    "    vote= max(temp,key=temp.count)#多數決\n",
    "    if vote==y_test.iloc[i]:\n",
    "        acc_count+=1\n",
    "        \n",
    "print(\"acc : \",acc_count/bag_predict.shape[1] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
